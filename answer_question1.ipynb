{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Analyse des métriques proposées pas les stagiaires (spoiler : on peut mieux faire)\n",
    "\n",
    "## Analyse de la loss\n",
    "\n",
    "## Analyse de la précision :\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cette metrique est souvent la première montrée dans tous les projets d'apprentissage. Si on prend l'exemple d'un classificateur de photo chat/chien, la précision représente le pourcentage de photo reconnue comme chat et qui sont effectivement des félins (\\#teamchat) et le nombre de photos chien et qui sont effectivement des canidés. Dans le cadre d'un algorithme multi classe la précision n'est simplement que la moyenne des précisions de toutes les classes. Dans notre cas nous avons donc 88,3% des intentions qui sont bien attribuée dans leur classes. Ce chiffre est plutôt élevé et donc de prime abord il semble que le modèle soit bon. Mais ne nous laissons pas avoir. Quid de l'état pour chaque classe. Y a t il des disparité ? Le dataset est il équilibré ? Sans cette information capitale la précision ne vaut pas grand chose (si on a 90% d'image de chien dans un dataset et que je suis un algorithme qui répond tout le temps chien lorsque je vois une image, ma précision vaudra 90%, trop fort). Avec cet exemple on voit bien que sans visualisation préalable des données cette valeur élevée ne vaut pas grand chose.\n",
    "\n",
    "## Analyse du recall \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Que signifie recall ? Rappel ! Le recall est en fait le pourcentage d'intention correctement classée par rapport au total d'intention qui appartiennent à la classe. Pour un système multi-classe, là encore, le recall correspond à la moyenne de recall de chaque classe. Cette donnée est très importante et va de pair avec la précision précédemment étudiée. Par exemple si on reprend l'exemple précédemment énoncé (l'algorithme qui ne dit que chien), on remarque que l'on aura alors un recall de 100\\% pour la classe chien mais un recall de 0\\% pour la classe chat. En moyennant (la moyenne n'est d'ailleurs peut être pas la meilleure chose à faire ici, notez l'ouverture vers un point qui sera **développé plus bas**)on obtient un recall de 50\\%. Ce chiffre désastreux contraste fortement avec son homologue 90\\% et nous montre bien toute l'importance du recall quant à la démonstration de la qualité du modèle. Le recall fourni par le README fait état d'une valeur de 66\\% ce qui est assez bas et qui est bien différent des 88\\% de précision. On peut donc en déduire que certaines classes doivent donc être moins bien traitée que d'autre. Mais alors (reprise de l'ouverture) il faudrait afficher le recall propre à chaque à classe et vérifier l'équilibre des données (en fait le dataset est très déséquilibré, 66\\% des données sont classifiées irrelevant ce qui rend très probable l'hypothèse de lacune dans certaines classes). \n",
    "    \n",
    "\n",
    "## Analyse de la métrique F1\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Le recall et la précision ont la même importance dans le calcul du $F_{1}$. Ce score va avoir le rôle de synthétiser à la fois les valeurs de recall et de précision. Cet indicateur peut être intéressant. Cependant dans notre cas on a vu que le recall avait beaucoup plus d'importance que la précision. Ainsi cet indicateur va donc nous donner une aide plutôt limitée mais qui est qui est là quand même. On pourrait donc utiliser une autre valeur pour le beta du fbeta score, qui refleterait l'importance que l'on accorde au recall. Il s'agirait alors d'une metric encore plus pertinente vu le déséquilibre du dataset (66% du volume des données est dans la classe *irrelevant*)\n",
    "\n",
    "# Analyses et visualisations manquantes\n",
    "\n",
    "## Analyses manquantes:\n",
    "Nous avons listé plusieurs analyses qui pourraient nous aider à mieux évaluer notre modèle :\n",
    "1. Utiliser un $F_{2}$ score plutôt qu'un $F_{1}$ score?\n",
    "    * Ce score correspondrait à un compromis entre le recall et la précision. Cependant l'avantage du $F_{2}$ sur le $F_{1}$ est qu'il met plus en lumière la partie recall. Ainsi on mettrait donc en avant un chiffre qui résume grossièrement les performances du modèles sur des métriques qui sont plus intéressantes pour notre problème.\n",
    "\n",
    "2. Un tableau présentant le recall pour chaque classe et la précision pour chaque classe\n",
    "    * Ce tableau permettrait de repérer les classes à problèmes. On a vu dans notre analyse en haut que le recall moyen n'était pas très bon, et on en avait déduit qu'il y avait certainement certaines classe qui posaient problème. Grâce à ces tableaux nous pourrions repérer explicitement ces classes.\n",
    "    * Dans le cadre d'une démonstration de fonctionnement cette metrics montre au client que le produit n'alloue pas moins d'importance à certaine classe (il n'est pas très fort sur une partie des classe ce qui lui permet d'avoir une bonne moyenne, alors qu'il est proche du  niveau 0 sur d'autres classes).\n",
    "\n",
    "3. Une matrice de confusion\n",
    "    * Cette matrice permettrait pour chaque classe de représenter les réponses données par l'algorithme en comparaison avec les résultats attendus pour chaque classes. Il serait alors intéressant d'étudier d'éventuelles disparités dans les classes (imaginons l'exemple où 80\\% des *find-train* sont classés dans *irrelevant*). Ce travail permettrait d'approfondir les résultats obtenus avec la méthode précédente (on se focaliserai sur les classes repérées grâce à leur recall insuffisant)\n",
    "    \n",
    "4. Une courbe AUC-ROC\n",
    "    * L'un des objectifs est d'obtenir le meilleur coefficient de threshold possible. Pour ce faire une courbe montrant l'évolution du taux de Vrai positif par rapport au taux de Faux positif serait quelque chose qui pourrait être idoine. C'est justement le rôle de la courbe AUC-ROC. Cette métrique permettrait donc pour le développeur de choisir le meilleur threshold possible, mais aussi de prouver l'efficacité de son seuillage. Il montrerait que le seuillage n'est pas trop fort (trop d'intent classé comme irrelevant) ni trop faible (trop d'intent classés dans des cases ne correpondant pas mais différentes d'irrelevant). Dans le cadre de l'exercice avoir un seuil bien posé est donc quelque chose de vital et critique pour l'application. En effet le client veut un algorithme qui puisse aider le plus possible l'utilisateur, mais il a aussi préciser qu'il veut éviter les redirections vers de mauvais formulaire, préférant un irrelevant à un mauvais formulaire. Bien placé, le threshold revient donc à équilibrer à la fois l'aide à l'utilisateur et l'évitement d'envoi de formulaire innaproprié.\n",
    "\n",
    "5. La métrique Cleymevin (invention)\n",
    "    * Cette métrique permettrait de pousser un peu plus loin l'analyse proposée par le courbe AUC-ROC. Cette métrique mesurerait en fait pour chaque classe le nombre de réponse qui ont amené la génération d'un mauvais formulaire. Cette métrique répond directement à la problématique énoncé par le client (à savoir éviter la génération d'un mauvais formulaire, quitte à faire appel à un opérateur humain). Elle permet de mettre sous silence les irrelevant qui \"gênent\" moins dans expérience utilisateur.\n",
    "\n",
    "<!-- Matrice de confusion\n",
    "-> Matrice des recalls et des précisions\n",
    "-> Courbe AUC-ROC\n",
    "-> fbeta avec beta > 1  => f2 score -->\n",
    "\n",
    "## Visualisations manquantes\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Analyser et étudier les données sur lesquelles sont réalisées les tests est vital pour la bonne réalisation du projet. Pour pouvoir comprendre comment ces données fonctionne il est possible d'ajouter la mesure dun nombre d'utérrance. Ce nombre indiquerait la taille de données sur laquelle l'algorithme s'entraîne. Cela permettrait de donner une bonne indication sur le degré de précision pouvant être atteint par l'algorithme sur chaque classe (on aura pas les mêmes attentes si on peut s'entraîner sur 10 000 images ou sur 10).\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Le nombre d'utternances par classe est aussi une données qui doit être évaluée. En effet avec le nombre d'utternance on a donc un ordre de grandeur de la taille globale du dataset. Mais comme on l'a vu précédemment, le dataset est assez hétéroclite. Et chacune des classes présente des comportements différents. En lien avec l'analyse du recall il est impérieux de comprendre la taille de chacune des classes. Ainsi on pourra donc s'appesantir sur ses classes en priorités pour vérifier les résultats de l'agent apprenant.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Il pourrait aussi être intéressant d'analyser l'hétérogénéïté des données (est ce que les phrases labellisées *find-hotel* toutes les phrases se ressemblent ou est ce qu'elles représentent plutôt bien la diversité du langage humain). Cependant, dans notre cas cette analyse risque d'être bien compliquée voire impossible (qu'est ce qui sémantiquement différencie deux phrases, changer un mot peut dans certains cas changer tout le sens et dans d'autre cas n'avoir aucune influence). Dans le cadre de l'exercice on va donc supposer que les datasets inter classe ont été bien construit par les linguiste pour offrir une diversité naturelle et nécessaire.\n",
    "\n",
    "-> Répartitions des données (nombre d'utterances par classes, nombres d'utterrances)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Récupération des résultats du modèle sur le dataset de test\n",
    "\n",
    "On a, au préalable, lancé l'image docker fourni par les stagiaires de l'année dernière qui contient un webservice permettant de connaitre les prédictions de leur model. Nous enregistrons ces prédictions dans un fichier predict.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/intent?sentence=Tu%20sais%20o%C3%B9%20je%20peux%20acheter%20un%20bazooka%20? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88506d6940>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             raise NewConnectionError(\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f88506d6940>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    727\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/intent?sentence=Tu%20sais%20o%C3%B9%20je%20peux%20acheter%20un%20bazooka%20? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88506d6940>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-76379c075c70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://localhost:8080/api/intent?sentence=\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://localhost:8080/api/intent?sentence=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mdata_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/intent?sentence=Tu%20sais%20o%C3%B9%20je%20peux%20acheter%20un%20bazooka%20? (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f88506d6940>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('testing_set.json') as f:\n",
    "   data = json.load(f)\n",
    "\n",
    "data_set = {}\n",
    "url = \"http://localhost:8080/api/intent?sentence=\"\n",
    "for i in range (len(data)):\n",
    "\tr = requests.get(\"http://localhost:8080/api/intent?sentence=\"+data[i][\"sentence\"])\n",
    "\tdata_set[i] = r.text\n",
    "\n",
    "with open('predict.json', 'w') as outfile:\n",
    "    json.dump(data_set, outfile,indent=4, sort_keys=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preprocessing pour les stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Stats by intent (detectedCorrect/detectedTotal   |  realCount)\n",
      "global  :  857 / 1065    totalInCatergory :  1065\n",
      "irrelevant  :  663 / 839    totalInCatergory :  677\n",
      "purchase  :  67 / 85    totalInCatergory :  114\n",
      "find-restaurant  :  52 / 53    totalInCatergory :  93\n",
      "find-train  :  14 / 15    totalInCatergory :  21\n",
      "find-around-me  :  29 / 33    totalInCatergory :  67\n",
      "find-hotel  :  21 / 27    totalInCatergory :  55\n",
      "provide-showtimes  :  4 / 5    totalInCatergory :  14\n",
      "find-flight  :  7 / 8    totalInCatergory :  24\n"
     ]
    }
   ],
   "source": [
    "with open('predict.json') as f:\n",
    "    predictions = json.load(f)\n",
    "with open('testing_set.json') as f:\n",
    "   test_dataset = json.load(f)\n",
    "\n",
    "def getDetectedIntent(prediction):\n",
    "    return max(prediction, key=lambda x: prediction[x])\n",
    "\n",
    "\n",
    "def increaseValue(dic, key):\n",
    "    if key in dic:\n",
    "        dic[key] += 1\n",
    "    else:\n",
    "        dic[key] = 1\n",
    "\n",
    "def getStatsByIntent(dataset, predictions):\n",
    "    statsByIntent = {}\n",
    "    statsByIntent[\"global\"] = {}\n",
    "    for i in range(len(dataset)):\n",
    "        detectedIntent = getDetectedIntent(predictions[str(i)])\n",
    "        realIntent = dataset[i][\"intent\"]\n",
    "        if realIntent not in statsByIntent:\n",
    "            statsByIntent[realIntent] = {}\n",
    "        if detectedIntent not in statsByIntent:\n",
    "            statsByIntent[detectedIntent] = {}\n",
    "        if detectedIntent == realIntent:\n",
    "            increaseValue(statsByIntent[detectedIntent], \"detectedTrue\")\n",
    "            increaseValue(statsByIntent[\"global\"], \"detectedTrue\")\n",
    "        increaseValue(statsByIntent[realIntent], \"trueCount\")\n",
    "        increaseValue(statsByIntent[detectedIntent], \"detectedTotal\")\n",
    "        increaseValue(statsByIntent[\"global\"], \"detectedTotal\")\n",
    "        increaseValue(statsByIntent[\"global\"], \"trueCount\")\n",
    "    return statsByIntent\n",
    "\n",
    "print(\"\\n Stats by intent (detectedCorrect/detectedTotal   |  realCount)\")\n",
    "statsByIntent = getStatsByIntent(test_dataset, predictions)\n",
    "for intent in statsByIntent.keys():\n",
    "    print(intent, \" : \", statsByIntent[intent][\"detectedTrue\"], \"/\", statsByIntent[intent][\"detectedTotal\"], \"   totalInCatergory : \", statsByIntent[intent][\"trueCount\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Calcul des métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-db0573c21a26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m#compute_scores(y_pred,y_true,lst_classe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m#plot_confusion_matrix(y_pred,y_true,lst_classe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mcompute_roc_auc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst_classe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-db0573c21a26>\u001b[0m in \u001b[0;36mcompute_roc_auc_curve\u001b[0;34m(lst_classe, pas, y_pred, y_true)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst_classe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpas\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mmaxi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'irrelevant'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst_classe\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# pour chaque intent (à vérifier) :\n",
    "# TP = statsByIntent[intent][\"detectedCorrect\"]\n",
    "# FP = statsByIntent[intent][\"detectedTotal\"] - statsByIntent[intent][\"detectedCorrect\"]\n",
    "# TP + FN = statsByIntent[intent][\"trueCount\"]\n",
    "# precision = TP / (TP + FP)\n",
    "# recall =  TP / (TP + FN)\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def compute_scores(y_pred,y_true,lst_classe) :\n",
    "    scores = sklearn.metrics.precision_recall_fscore_support(y_pred, y_true, beta = 2, labels = lst_classe,average=None)\n",
    "    print(\"classe      Precision      Recall      F2Score\")\n",
    "    for i in range(len(lst_classe)) :\n",
    "        print(lst_classe[i]+'   ',end='')\n",
    "        print(str(scores[0][i])+'      ',end='')\n",
    "        print(str(scores[1][i])+'      ',end='')\n",
    "        print(str(scores[2][i])+'      ',end='')\n",
    "        print(\"\\n\")\n",
    "    return\n",
    "\n",
    "def plot_confusion_matrix(y_pred, y_true, lst_classe) :\n",
    "    cm = sklearn.metrics.confusion_matrix(y_pred, y_true)\n",
    "    ax = matplotlib.pyplot.subplot()\n",
    "    sns.heatmap(cm, annot = True, ax=ax)\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(lst_classe)\n",
    "    lst_classe.reverse()\n",
    "    ax.yaxis.set_ticklabels(lst_classe)\n",
    "    return\n",
    "\n",
    "def compute_roc_auc_curve(lst_classe, pas, y_pred, y_true) :\n",
    "    dic = {}\n",
    "    for i in lst_classe :\n",
    "        dic[i] = [[],[]]\n",
    "    n_classes = lst_classe\n",
    "    ind = 0\n",
    "    \n",
    "    for threshold in range(0.01,) :\n",
    "        maxi = 'irrelevant'\n",
    "        for i in lst_classe :\n",
    "            dic[i][0].append(0)\n",
    "            dic[i][1].append(0)\n",
    "        for l in range(len(y_pred)) :\n",
    "            lst_predicted = []\n",
    "            for j in lst_classe :\n",
    "                if(y_pred[l][j] > threshold) :\n",
    "                    lst_predicted.append(j)\n",
    "            for j in lst_predicted :\n",
    "                if(y_true[l] == j) :\n",
    "                    dic[j][0][ind] += 1\n",
    "                else :\n",
    "                    dic[j][1][ind] += 1\n",
    "        ind += 1\n",
    "    for i in lst_classe :\n",
    "        print((dic[i][0],dic[i][1]))\n",
    "        dic[i] = [0 if((dic[i][0][j]+dic[i][1][j])==0) else float(dic[i][0][j])/(dic[i][0][j]+dic[i][1][j]) for j in range(len(dic[i][0]))]\n",
    "        to_plot = [range(1,100,pas),dic[i]]\n",
    "        print(to_plot)\n",
    "        sns.lineplot(np.asarray(to_plot))\n",
    "        #Plus qu'à faire l'affichage des courbes. La fonction Cleymevin devrait pas mal ressembler d'ailleurs\n",
    "\n",
    "def Cleymevin_curve(lst_classe, pas, y_pred, y_true) :\n",
    "    dic = {}\n",
    "    for i in lst_classe :\n",
    "        dic[i] = [[],[]]\n",
    "    n_classes = lst_classe\n",
    "    ind = 0\n",
    "    for threshold in range(0.01,1,pas) :\n",
    "        maxi = 'irrelevant'\n",
    "        for i in lst_classe :\n",
    "            dic[i][0].append(0)\n",
    "            dic[i][1].append(0)\n",
    "        for l in range(len(y_pred)) :\n",
    "            for j in lst_classe :\n",
    "                print(y_pred[l])\n",
    "                if(y_pred[l][j] > threshold) :\n",
    "                    if(maxi == 'irrelevant' ) :\n",
    "                        maxi = j\n",
    "                    if(j == 'irrelevant') :\n",
    "                        maxi = 'irrelevant'\n",
    "                        break\n",
    "                    else :\n",
    "                        maxi = 'irrelevant'\n",
    "                        break\n",
    "            if(y_true[l] == maxi or maxi == 'irrelevant') :\n",
    "                dic[maxi][0][ind] += 1\n",
    "            else :\n",
    "                dic[maxi][1][ind] += 1\n",
    "        ind += 1\n",
    "    for i in lst_classe :\n",
    "        print(i)\n",
    "        print(dic[i])\n",
    "        dic[i] = [j[0]/(j[0]+j[1]) for j in dic[i]]\n",
    "        to_plot = [range(1,100,pas),dic[i]]\n",
    "        sns.lineplot(to_plot)\n",
    "        #Plus qu'à faire l'affichage des courbes. La fonction Cleymevin devrait pas mal ressembler d'ailleurs\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_pred_all = []\n",
    "lst_classe = [\"find-around-me\",\"find-flight\",\"find-hotel\",\"find-restaurant\",\"find-train\",\"irrelevant\",\"provide-showtimes\",\"purchase\"]\n",
    "pas = 0.01\n",
    "for i in range(len(test_dataset)):\n",
    "    y_pred.append(getDetectedIntent(predictions[str(i)]))\n",
    "    y_true.append(test_dataset[i][\"intent\"])\n",
    "    y_pred_all.append(predictions[str(i)])\n",
    "\n",
    "\n",
    "#compute_scores(y_pred,y_true,lst_classe)\n",
    "#plot_confusion_matrix(y_pred,y_true,lst_classe)\n",
    "compute_roc_auc_curve(lst_classe,pas,y_pred_all,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Affichage des métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}