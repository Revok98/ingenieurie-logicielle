{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "from spacy.util import minibatch\n",
    "from spacy.util import compounding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fr_core_news_sm==2.3.0 from https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.3.0/fr_core_news_sm-2.3.0.tar.gz#egg=fr_core_news_sm==2.3.0 in /home/revok/.local/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/revok/.local/lib/python3.8/site-packages (from fr_core_news_sm==2.3.0) (2.3.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/revok/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.18.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/revok/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (2.0.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/revok/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/revok/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/revok/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /home/revok/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (0.7.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/revok/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (4.52.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/revok/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.0.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (45.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (2.22.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/revok/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/revok/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (7.4.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/revok/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (0.8.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download fr_core_news_sm\n",
    "import fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = fr_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>850€ maximum pour le loyer, à partir de janvie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>D'imprimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purchase</td>\n",
       "      <td>Le meilleur cabriolet hybrid moins de 5m10 min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>find-hotel</td>\n",
       "      <td>en ce moment je cher un location pour les vaca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irrelevant</td>\n",
       "      <td>c'est possible de t'utiliser la nuit ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intent                                           sentence\n",
       "0  irrelevant  850€ maximum pour le loyer, à partir de janvie...\n",
       "1  irrelevant                                         D'imprimer\n",
       "2    purchase  Le meilleur cabriolet hybrid moins de 5m10 min...\n",
       "3  find-hotel  en ce moment je cher un location pour les vaca...\n",
       "4  irrelevant             c'est possible de t'utiliser la nuit ?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_json('data/training_set.json')\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6035, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6035 entries, 0 to 6034\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   intent    6035 non-null   object\n",
      " 1   sentence  6035 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 94.4+ KB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "irrelevant           3852\n",
       "purchase              613\n",
       "find-restaurant       469\n",
       "find-around-me        383\n",
       "find-hotel            316\n",
       "find-train            143\n",
       "find-flight           142\n",
       "provide-showtimes     117\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df[\"intent\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = training_df[\"sentence\"]\n",
    "train_y = training_df[\"intent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_regex = re.compile(r\"\"\"(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vouloir', 'pouvoir', 'trouver', 'site', 'carte', 'postal', 'fête', 'mère']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_data_cleaning(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.lemma_ != \"-PRON-\":\n",
    "            temp = token.lemma_.lower().strip()\n",
    "        else:\n",
    "            temp = token.lower_\n",
    "        tokens.append(temp)\n",
    "    \n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words and token not in punct and emoticon_regex.match(token) == None :\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens\n",
    "text_data_cleaning(\"   Je veux bien , tu peux trouver un site de carte postale pour la fête des mères :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2list(text_df, label_df):\n",
    "    res_list = [(text_df.iloc[i], {'cats': label_df.iloc[i]}) for i in range(len(text_df))]\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list = df2list(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner', 'textcat']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cat=nlp.create_pipe( \"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"})\n",
    "nlp.add_pipe(text_cat, last=True)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(training_df[\"intent\"]):\n",
    "    text_cat.add_label(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for itn in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(training_list)\n",
    "    losses = {}\n",
    "\n",
    "    # Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(training_list, size=1):\n",
    "        texts = [nlp(text) for text, entities in batch]\n",
    "        annotations = [{\"cats\": entities} for text, entities in batch]\n",
    "        nlp.update(texts, annotations, losses=losses)\n",
    "    if itn % 20 == 0:\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
